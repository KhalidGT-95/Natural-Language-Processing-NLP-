{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name : Syed Khalid Ahmed\n",
    "#### Marticulation number : 276970"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER) using Python and nltk-trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, I have used nltk-trainer, which is an open-source tool for Natural Language Processing. I have used their scripts to train the models using Naive Bayes classifier. I tried to implement the algorithm by myself on the available data but I was not able to model the whole process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagger function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have implemented a POS tagger for tagging words to be used in NER algorithm. I have followed the link on nltk website and create a combined tagger. \n",
    "\n",
    "The file POS-tagger.py contains the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accracy on the test data comes out to be : 0.9174493952761889\n",
      "\n",
      "Dumped the data in a file for later use\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import conll2000 \n",
    "from pickle import dump\n",
    "\n",
    "## Here I have implemented a combined tagger to increase the accuracy of the tagger\n",
    "def BackoffTaggers(train_data,test_data):\n",
    "\n",
    "    Default_tagger = nltk.DefaultTagger('NN')\n",
    "    Unigram_tagger = nltk.UnigramTagger(train_data, backoff=Default_tagger)\n",
    "    Bigram_tagger = nltk.BigramTagger(train_data, backoff=Unigram_tagger)\n",
    "\n",
    "    print(\"\\nAccracy on the test data comes out to be : \",end='')\n",
    "    print(Bigram_tagger.evaluate(test_data))  # Evaluating the accuracy on test data  \n",
    "    \n",
    "    ## Dump the tagger in a file to be used later\n",
    "    output = open('tagged_data.pkl','wb')\n",
    "    dump(Bigram_tagger,output, -1)\n",
    "    output.close()\n",
    "    \n",
    "    print(\"\\nDumped the data in a file for later use\")\n",
    "\n",
    "## Function to read the CONLL corpus\n",
    "def read_conll(path):\n",
    "    result = []\n",
    "    file = open(path)\n",
    "    sent = []\n",
    "    for line in file:\n",
    "        line = line.strip('\\n')\n",
    "        if not line.strip(' '):\n",
    "            result.append(sent)\n",
    "            sent = []\n",
    "            continue\n",
    "        (word,pos,tag) = line.split(' ')\n",
    "        sent.append((word,pos))     # storing only word and POS to train the tagger\n",
    "    return result\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "\n",
    "    conll_train = read_conll('train.txt')   # Read the CONLL training text\n",
    "    conll_test = read_conll('test.txt')     # Read the CONLL testing text\n",
    "\n",
    "    BackoffTaggers(conll_train,conll_test)  # Call the function\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I have used the script provided by the nltk-trainer library to train the Naive-Bayes classifier on the training data of the CONLL2000 corpus. I have attached the relevant screenshot also\n",
    "\n",
    "![title](Training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the above generated objects from POS tagger function and Named Entity Recognition function, we can now combine them and create a NER program.\n",
    "\n",
    "The file Main_Program.py contains the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Germany/NNP)\n",
      "  (VP is/VBZ)\n",
      "  (NP a/DT very/RB beautiful/JJ country/NN))\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import pickle\n",
    "from pickle import load\n",
    "import nltk\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    file = open('tagged_data.pkl','rb')     # Open the file containing the POS tagger\n",
    "\n",
    "    POS_tagger = pickle.load(file)          # Load the tagger object using pickle\n",
    "\n",
    "    ## Load the saved NER classifier object\n",
    "    ## This file was generated by the nltk-trainer python script which\n",
    "    ## generates a Naive-Bayes trained classifier\n",
    "    NER_classifier = nltk.data.load(('conll2000_NaiveBayes.pickle'))    \n",
    "\n",
    "    string = \"Germany is a very beautiful country\".split()\n",
    "\n",
    "    ## Tag the words using the previously made tagger\n",
    "    tagged_data = POS_tagger.tag(string)\n",
    "\n",
    "    ## Find the named entities using the NER classifier and the tagger\n",
    "    output = NER_classifier.parse(tagged_data)\n",
    "\n",
    "    ## Print the output\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As seen in the output, the program separates the named entities. \"Germany\" is a noun and \"a very beautiful country\" is also separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
