{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name : Syed Khalid Ahmed\n",
    "#### Marticulation number : 276970"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Identification using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program identifies 4 languages using n-grams technique. I have used the udhr corpus for English, German, Italian and Spanish. To further improve the accuracy, I have also used news text in these languages. I will now describe the logic and flow of the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I started by importing the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import udhr\n",
    "import math\n",
    "from decimal import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I have declared the dictionaries to store the n-grams of input text as well as the udhr corpus for each language. I saved these dictionaries in a list so that it easy to manipualte them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "udhr_store_english = dict()\n",
    "udhr_store_german = dict()\n",
    "udhr_store_italian = dict()\n",
    "udhr_store_spanish = dict()\n",
    "\n",
    "stores = [udhr_store_english,udhr_store_german,udhr_store_italian,udhr_store_spanish]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This array stores the name of the dictionaries sequentially so that it becomes easier to access the above dictionaries later in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['English','German','Italian','Spanish']\n",
    "weight = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the N-grams of the given text passed as an argument. The choice argument represents for which type we want the function to work for. For example: If choice is 0 then this means that the text is input, so save it in the relevant dictionary. If choice is greater than 0 then we would save the n-grams in the relevant index of list \"stores\". Since each element of the list contains a dictionary, therefore we would save the n-grams of the text in the respective list index dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NgramCalculator(text,choice):\n",
    "\n",
    "    input_store = dict()\n",
    "    global stores\n",
    "    global names\n",
    "    global weight\n",
    "    \n",
    "    # Taking 3 gram\n",
    "    weight = 3\n",
    "\n",
    "    if choice == 0:                          # For Input \n",
    "        for i in range(len(text)):           # Loop until the length of the text   \n",
    "            temp = text[i:i+weight].strip().lower()     # Produce n-grams, strip the whitespaces and convert into lowercase\n",
    "\n",
    "            #if len(temp) < weight-1:\n",
    "            #    continue\n",
    "            \n",
    "            if temp in input_store:     # If the n-gram is already in the store    \n",
    "                input_store[temp] += 1  # Increment its count by 1\n",
    "\n",
    "            else:                       # If appearing for the first time\n",
    "                input_store[temp] = 1   # Create a key of it and assign a value of 1\n",
    "\n",
    "        CosineSimilarity(input_store)   # Call this function to find the Cosine Similarity\n",
    "        \n",
    "    else:                               # For language corpora\n",
    "        for i in range(len(text)):\n",
    "            \n",
    "            temp = text[i:i+weight].strip().lower()    # Produce n-grams, strip the whitespaces and convert into lowercase\n",
    "\n",
    "            ## The following lines perform text cleanup by removing special characters,\n",
    "            ## numbers, tabs and newline characters from the text. Since these do not\n",
    "            ## help in language identification, so it is better to remove them. \n",
    "            ## Now the n-grams contain values which are of most interest. \n",
    "\n",
    "            temp = re.sub('[,!@#$-]','',temp)        \n",
    "            temp = re.sub('[0-9]','',temp)\n",
    "            temp = re.sub('\\t',' ',temp)\n",
    "            temp = re.sub('\\n',' ',temp).strip()\n",
    "\n",
    "            #########################################################\n",
    "            \n",
    "            #if len(temp) < weight-1:\n",
    "            #    continue\n",
    "\n",
    "            # Since the stores is a list and each on each index is a dictionary\n",
    "            # so we can perform a dictionary lookup\n",
    "            \n",
    "            if temp in stores[choice-1]:            \n",
    "                stores[choice-1][temp] += 1\n",
    "            else:\n",
    "                stores[choice-1][temp] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function performs a cross check on other dictionaries for a given n-gram of input text. If an n-gram appears in only one dictionary, then it is highly probable that the letters appearing in that n-gram are unique for that language. For example: The german umlauts (ö,ß,ä,ü) are unique to german language. Hence if they appear in an n-gram and not in any other dictionary, then we can say that the input belongs to german. \n",
    "\n",
    "The argument 'key' represents the n-gram and the argument 'dict_index' represents the dictionary which is currently used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Lookup(key,dict_index):\n",
    "    global stores\n",
    "    global names\n",
    "\n",
    "    for i in range(len(stores)):    # Loop through the available dictionaries    \n",
    "        if i == dict_index:         # If on the same dictionary as the language, skip it since we are interested in finding the n-gram in other dictionaries\n",
    "            continue\n",
    "        \n",
    "        if key in stores[i]:        # If the n-gram is also present in another dictionary, then it is common among languages and hence of no interest\n",
    "            return False            # immediately return false\n",
    "\n",
    "    return True                     # If not present in any other dictionary, return true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function finds the cosine similarity between two languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CosineSimilarity(input_store):\n",
    "\n",
    "    global stores\n",
    "    global names\n",
    "    global weight\n",
    "\n",
    "    print(\"\\t\\t\\t\\t\\tStatistics :\\n\")\n",
    "\n",
    "    ## Loop through all the number of dictionaries present    \n",
    "    ## Since there are 4 dictionaries, so this loop will run from 0-3\n",
    "    for i in range(len(stores)):\n",
    "        numerator = 0           # Numerator = 0 for each iteration             \n",
    "        denominator = 0         # Numerator = 0 for each iteration\n",
    "        TrainingData_temp = 0   # Training data values\n",
    "        TestingData_temp = 0    # Testing data values\n",
    "\n",
    "        ## Loop through each key-value pair in the input n-gram dictionary\n",
    "        for key,value in input_store.items():\n",
    "\n",
    "            # If the key is present in the language dictionary    \n",
    "            if key in stores[i]:\n",
    "                if Lookup(key,i):   # Perform a lookup on other dictionaries, if it is true then\n",
    "                    numerator += (value * int(stores[i][key])) ** 2     # Raise the power of numerator by 2 since it is highly probably that the current language is same as input\n",
    "                    TrainingData_temp += value**2\n",
    "                    TestingData_temp += int(stores[i][key]) ** 2\n",
    "\n",
    "                else:\n",
    "                    numerator += (value * int(stores[i][key]))\n",
    "                    TrainingData_temp += value**2\n",
    "                    TestingData_temp += int(stores[i][key]) ** 2\n",
    "            else:\n",
    "                numerator += (value * 0)\n",
    "                TrainingData_temp += value**2\n",
    "                TestingData_temp += 0\n",
    "                \n",
    "        denominator = math.sqrt(TrainingData_temp) * math.sqrt(TestingData_temp)\n",
    "\n",
    "        try:\n",
    "            cos_theta = numerator / denominator\n",
    "            if cos_theta >= 0.99:       # If the score reaches above 99%\n",
    "                cos_theta = 0.99        # Clip it to 99%\n",
    "\n",
    "            print(\"For \" + names[i] + \", similarity percentage is: \")\n",
    "            print(str(round(cos_theta*100,3)) + \" % \\n\")\n",
    "\n",
    "        except ZeroDivisionError:       # Thrown when no word matches. For Example : süß will never appear in english\n",
    "            print(\"No matching word in \"+names[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function reads data from udhr corpora as well as news texts and passes those to the N-Gram function which then generates the N-grams for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Training():\n",
    "\n",
    "    global weight\n",
    "    \n",
    "    print(\"\\nTraining the model using the given data , Please Wait . . . \\n\")\n",
    "\n",
    "    ## Read the corpora\n",
    "    english = udhr.raw(\"English-Latin1\")\n",
    "    german = udhr.raw(\"German_Deutsch-Latin1\")\n",
    "    italian = udhr.raw(\"Italian-Latin1\")\n",
    "    spanish = udhr.raw(\"Spanish-Latin1\")\n",
    "\n",
    "    ## Pass these to NgramCalculator to calculate n-grams\n",
    "    NgramCalculator(english,1)\n",
    "    NgramCalculator(german,2)\n",
    "    NgramCalculator(italian,3)\n",
    "    NgramCalculator(spanish,4)\n",
    "\n",
    "    print(\"Taking \"+str(weight)+\" grams\")\n",
    "\n",
    "    ## Read the news files sequentially \n",
    "    for i in range(len(names)):\n",
    "        filename = names[i]+\".txt\"\n",
    "        string = \"\"\n",
    "        with open(filename,encoding=\"utf-8\") as file:\n",
    "            content = file.readlines()\n",
    "            for line in content:\n",
    "                string += \"\".join(line)     # Append to the string\n",
    "        \n",
    "        NgramCalculator(string,i+1)\n",
    "\n",
    "\n",
    "    print(\"\\nTraining Completed . . .\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes input from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TakeInput():\n",
    "\n",
    "    while True:\n",
    "        print(\"Please enter a string to find its language similarity (press 'q' to quit) \\n\")\n",
    "        string = str(input(\"--> \"))\n",
    "\n",
    "        if string.strip() == 'q':\n",
    "            print(\"\\nGoodbye :)\")\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            NgramCalculator(string.strip(),0)   # Pass this to N-gram function with code 0 specifying this as an input text\n",
    "            print(\"____________________________________________________\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the model using the given data , Please Wait . . . \n",
      "\n",
      "Taking 3 grams\n",
      "\n",
      "Training Completed . . .\n",
      "\n",
      "Please enter a string to find its language similarity (press 'q' to quit) \n",
      "\n",
      "--> Hello world\n",
      "\t\t\t\t\tStatistics :\n",
      "\n",
      "For English, similarity percentage is: \n",
      "75.965 % \n",
      "\n",
      "For German, similarity percentage is: \n",
      "42.75 % \n",
      "\n",
      "For Italian, similarity percentage is: \n",
      "52.161 % \n",
      "\n",
      "For Spanish, similarity percentage is: \n",
      "42.725 % \n",
      "\n",
      "____________________________________________________\n",
      "\n",
      "Please enter a string to find its language similarity (press 'q' to quit) \n",
      "\n",
      "--> das wetter ist gut\n",
      "\t\t\t\t\tStatistics :\n",
      "\n",
      "For English, similarity percentage is: \n",
      "68.187 % \n",
      "\n",
      "For German, similarity percentage is: \n",
      "54.687 % \n",
      "\n",
      "For Italian, similarity percentage is: \n",
      "63.036 % \n",
      "\n",
      "For Spanish, similarity percentage is: \n",
      "42.79 % \n",
      "\n",
      "____________________________________________________\n",
      "\n",
      "Please enter a string to find its language similarity (press 'q' to quit) \n",
      "\n",
      "--> ist gut nacht\n",
      "\t\t\t\t\tStatistics :\n",
      "\n",
      "For English, similarity percentage is: \n",
      "59.912 % \n",
      "\n",
      "For German, similarity percentage is: \n",
      "78.683 % \n",
      "\n",
      "For Italian, similarity percentage is: \n",
      "52.767 % \n",
      "\n",
      "For Spanish, similarity percentage is: \n",
      "47.629 % \n",
      "\n",
      "____________________________________________________\n",
      "\n",
      "Please enter a string to find its language similarity (press 'q' to quit) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Training()\n",
    "TakeInput()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
